{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9948a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import os.path\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad8c0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\Projects\\YELP\\data\\yelp_dataset.tar\"\n",
    "dataPath = r\"D:/Projects/YELP/data/\"\n",
    "# dataPath = os.path.join(\"D:\", \"Projects\",\"YELP\",\"Data\")\n",
    "# dataPath = Path(r\"D:\\Projects\\YELP\\data\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea883dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "file = tarfile.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab758fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting file\n",
    "file.extractall()\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fce937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_times(times):\n",
    "    if pd.isnull(times):\n",
    "        return None, None\n",
    "    times = times.split('-')\n",
    "    start_time = times[0]\n",
    "    end_time = times[1]\n",
    "    return start_time, end_time\n",
    "\n",
    "\n",
    "def createHoursFile(hoursDF):\n",
    "    main_hours = []\n",
    "    for index, rows in hoursDF.iterrows():\n",
    "        subdict = {'business_id':None,\n",
    "                   'Monday_Open':None, 'Monday_Close':None,\n",
    "                   'Tuesday_Open':None, 'Tuesday_Close':None,\n",
    "                   'Wednesday_Open':None, 'Wednesday_Close':None,\n",
    "                   'Thursday_Open':None, 'Thursday_Close':None,\n",
    "                   'Friday_Open':None, 'Friday_Close':None,\n",
    "                   'Saturday_Open':None, 'Saturday_Close':None,\n",
    "                   'Sunday_Open':None, 'Sunday_Close':None}\n",
    "        busID = rows['business_id']\n",
    "        subdict['business_id'] = busID\n",
    "        hRow = rows['hours']\n",
    "        if (pd.isnull(hRow)) or (hRow == 'null'):\n",
    "            main_hours.append(subdict)\n",
    "        else:\n",
    "#             hRow = ast.literal_eval(hRow)\n",
    "            for k,v in hRow.items():\n",
    "                if k == 'Monday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Monday_Open'] = openH\n",
    "                    subdict['Monday_Close'] = closeH\n",
    "                if k == 'Tuesday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Tuesday_Open'] = openH\n",
    "                    subdict['Tuesday_Close'] = closeH\n",
    "                if k == 'Wednesday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Wednesday_Open'] = openH\n",
    "                    subdict['Wednesday_Close'] = closeH\n",
    "                if k == 'Thursday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Thursday_Open'] = openH\n",
    "                    subdict['Thursday_Close'] = closeH\n",
    "                if k == 'Friday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Friday_Open'] = openH\n",
    "                    subdict['Friday_Close'] = closeH\n",
    "                if k == 'Saturday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Saturday_Open'] = openH\n",
    "                    subdict['Saturday_Close'] = closeH\n",
    "                if k == 'Sunday':\n",
    "                    openH, closeH = split_times(v)\n",
    "                    subdict['Sunday_Open'] = openH\n",
    "                    subdict['Sunday_Close'] = closeH\n",
    "            main_hours.append(subdict)\n",
    "    hoursDF = pd.DataFrame(main_hours)\n",
    "    return hoursDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29865f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_values(value):\n",
    "    if pd.isnull(value):\n",
    "        return\n",
    "    if type(value) == bool:\n",
    "        return value\n",
    "    if value.startswith(\"u'\"):\n",
    "        value = value.replace(\"u'\", \"\").replace(\"'\", \"\")\n",
    "        return value\n",
    "    elif value.startswith(\"'\"):\n",
    "        value = value.replace(\"'\", \"\")\n",
    "        return value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "\n",
    "def create_new_details(attDict, current_column):\n",
    "    if (attDict == 'None') or (pd.isnull(attDict)):\n",
    "        return\n",
    "    attDict = ast.literal_eval(attDict)\n",
    "    attDictApp = {}\n",
    "    for k1, v1 in attDict.items():\n",
    "        v1 = clean_values(v1)\n",
    "        k1 = current_column + '_' + k1\n",
    "        attDictApp[k1] = v1\n",
    "#     print(attDictApp)\n",
    "    return attDictApp\n",
    "\n",
    "\n",
    "def createAttributesData(attSub):\n",
    "    attDF = []\n",
    "    expander = ['BusinessParking', 'Ambience', 'GoodForMeal', 'Music', 'DietaryRestrictions', 'BestNights', 'HairSpecializesIn']\n",
    "    for ind, rows in attSub.iterrows():\n",
    "        subdict = {}\n",
    "        busID = rows['business_id']\n",
    "        subdict['business_id'] = busID\n",
    "        attsDict = rows['attributes']\n",
    "        if (pd.isnull(attsDict)) or (attsDict == 'null'):\n",
    "            attDF.append(subdict)\n",
    "        else:\n",
    "            for k,v in attsDict.items():\n",
    "                if k in expander:\n",
    "                    expandedAttrs = create_new_details(v, k)\n",
    "                    if type(expandedAttrs) == dict:\n",
    "                        subdict.update(expandedAttrs)\n",
    "                else:\n",
    "                    subdict[k] = v\n",
    "            attDF.append(subdict)\n",
    "    attributesDF = pd.DataFrame(attDF)\n",
    "    attributesDF['WiFi'] = attributesDF['WiFi'].apply(clean_values)\n",
    "    attributesDF['Alcohol'] = attributesDF['Alcohol'].apply(clean_values)\n",
    "    attributesDF['RestaurantsAttire'] = attributesDF['RestaurantsAttire'].apply(clean_values)\n",
    "    attributesDF['NoiseLevel'] = attributesDF['NoiseLevel'].apply(clean_values)\n",
    "    attributesDF['Smoking'] = attributesDF['Smoking'].apply(clean_values)\n",
    "    attributesDF['BYOBCorkage'] = attributesDF['BYOBCorkage'].apply(clean_values)\n",
    "    attributesDF['AgesAllowed'] = attributesDF['AgesAllowed'].apply(clean_values)\n",
    "    return attributesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2acab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_business():\n",
    "    lines = []\n",
    "    with open(dataPath + \"yelp_academic_dataset_business.json\", encoding=\"latin1\") as file:\n",
    "#     with open(\"D:\\Projects\\YELP\\data\\yelp_academic_dataset_business.json\", encoding=\"latin1\") as file:\n",
    "        for line in file:\n",
    "            line = line.replace('\\/', ' ').replace('\\n', '').replace(':null', ': \"null\"')\n",
    "            lines.append(line)\n",
    "#     lines = lines[:10000]\n",
    "    evaled = []\n",
    "    for i, line_ in enumerate(lines):\n",
    "        if i%10000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            newline = ast.literal_eval(line_)\n",
    "            evaled.append(newline)\n",
    "        except Exception as e:\n",
    "            print(line_)\n",
    "            print(e)\n",
    "            break\n",
    "    df = pd.DataFrame(evaled)\n",
    "    print(df.info())\n",
    "        \n",
    "    business = df[['business_id', 'name', 'address', 'city', 'state', 'postal_code', \n",
    "                   'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'categories']]\n",
    "\n",
    "    hours = df[['business_id', 'hours']]\n",
    "\n",
    "    attributes = df[['business_id', 'attributes']]\n",
    "    \n",
    "    print('Doing Business')\n",
    "    business.to_excel(dataPath + \"businessOnly.xlsx\", index=False)\n",
    "#     business.to_excel(\"D:\\Projects\\YELP\\data\\businessOnly.xlsx\", index=False)\n",
    "    \n",
    "    print('Doing Hours')\n",
    "    hoursDF = createHoursFile(hours)\n",
    "    hoursDF.to_csv(dataPath + \"businessHours.csv\", index=False)\n",
    "#     hoursDF.to_csv(\"D:\\Projects\\YELP\\data\\businessHours.csv\", index=False)\n",
    "    \n",
    "    print('Doing Attributes')\n",
    "    attributesDF = createAttributesData(attributes)\n",
    "    attributesDF.to_csv(dataPath + \"businessAttributesNew.csv\", index=False)\n",
    "#     attributesDF.to_csv(\"D:\\Projects\\YELP\\data\\businessAttributesNew.csv\", index=False)\n",
    "    return attributesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbb307a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150346 entries, 0 to 150345\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   business_id   150346 non-null  object \n",
      " 1   name          150346 non-null  object \n",
      " 2   address       150346 non-null  object \n",
      " 3   city          150346 non-null  object \n",
      " 4   state         150346 non-null  object \n",
      " 5   postal_code   150346 non-null  object \n",
      " 6   latitude      150346 non-null  float64\n",
      " 7   longitude     150346 non-null  float64\n",
      " 8   stars         150346 non-null  float64\n",
      " 9   review_count  150346 non-null  int64  \n",
      " 10  is_open       150346 non-null  int64  \n",
      " 11  attributes    150346 non-null  object \n",
      " 12  categories    150346 non-null  object \n",
      " 13  hours         150346 non-null  object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 16.1+ MB\n",
      "None\n",
      "Doing Business\n",
      "Doing Hours\n",
      "Doing Attributes\n"
     ]
    }
   ],
   "source": [
    "test = convert_business()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fbe9036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>ByAppointmentOnly</th>\n",
       "      <th>BusinessAcceptsCreditCards</th>\n",
       "      <th>BikeParking</th>\n",
       "      <th>RestaurantsPriceRange2</th>\n",
       "      <th>CoatCheck</th>\n",
       "      <th>RestaurantsTakeOut</th>\n",
       "      <th>RestaurantsDelivery</th>\n",
       "      <th>Caters</th>\n",
       "      <th>WiFi</th>\n",
       "      <th>...</th>\n",
       "      <th>Open24Hours</th>\n",
       "      <th>RestaurantsCounterService</th>\n",
       "      <th>AgesAllowed</th>\n",
       "      <th>DietaryRestrictions_dairy-free</th>\n",
       "      <th>DietaryRestrictions_gluten-free</th>\n",
       "      <th>DietaryRestrictions_vegan</th>\n",
       "      <th>DietaryRestrictions_kosher</th>\n",
       "      <th>DietaryRestrictions_halal</th>\n",
       "      <th>DietaryRestrictions_soy-free</th>\n",
       "      <th>DietaryRestrictions_vegetarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>u'no'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>u'free'</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id ByAppointmentOnly BusinessAcceptsCreditCards  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A              True                        NaN   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw               NaN                       True   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ             False                       True   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw             False                      False   \n",
       "4  mWMc6_wTdE0EUBKIGXDVfA               NaN                       True   \n",
       "\n",
       "  BikeParking RestaurantsPriceRange2 CoatCheck RestaurantsTakeOut  \\\n",
       "0         NaN                    NaN       NaN                NaN   \n",
       "1         NaN                    NaN       NaN                NaN   \n",
       "2        True                      2     False              False   \n",
       "3        True                      1       NaN               True   \n",
       "4        True                    NaN       NaN               True   \n",
       "\n",
       "  RestaurantsDelivery Caters     WiFi  ... Open24Hours  \\\n",
       "0                 NaN    NaN      NaN  ...         NaN   \n",
       "1                 NaN    NaN      NaN  ...         NaN   \n",
       "2               False  False    u'no'  ...         NaN   \n",
       "3               False   True  u'free'  ...         NaN   \n",
       "4                 NaN  False      NaN  ...         NaN   \n",
       "\n",
       "  RestaurantsCounterService AgesAllowed DietaryRestrictions_dairy-free  \\\n",
       "0                       NaN         NaN                            NaN   \n",
       "1                       NaN         NaN                            NaN   \n",
       "2                       NaN         NaN                            NaN   \n",
       "3                       NaN         NaN                            NaN   \n",
       "4                       NaN         NaN                            NaN   \n",
       "\n",
       "  DietaryRestrictions_gluten-free DietaryRestrictions_vegan  \\\n",
       "0                             NaN                       NaN   \n",
       "1                             NaN                       NaN   \n",
       "2                             NaN                       NaN   \n",
       "3                             NaN                       NaN   \n",
       "4                             NaN                       NaN   \n",
       "\n",
       "  DietaryRestrictions_kosher DietaryRestrictions_halal  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                       NaN   \n",
       "3                        NaN                       NaN   \n",
       "4                        NaN                       NaN   \n",
       "\n",
       "  DietaryRestrictions_soy-free DietaryRestrictions_vegetarian  \n",
       "0                          NaN                            NaN  \n",
       "1                          NaN                            NaN  \n",
       "2                          NaN                            NaN  \n",
       "3                          NaN                            NaN  \n",
       "4                          NaN                            NaN  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790927fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_user():\n",
    "    lines = []\n",
    "    with open(dataPath + \"yelp_academic_dataset_user.json\", encoding=\"latin1\") as file:\n",
    "#     with open(\"D:\\Projects\\YELP\\data\\yelp_academic_dataset_user.json\", encoding=\"latin1\") as file:\n",
    "        for line in file:\n",
    "            line = line.replace('\\/', ' ').replace('\\n', '').replace(':null', ': \"null\"')\n",
    "            lines.append(line)\n",
    "    evaled = []\n",
    "    for i, line_ in enumerate(lines):\n",
    "        if i%50000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            newline = ast.literal_eval(line_)\n",
    "            evaled.append(newline)\n",
    "        except Exception as e:\n",
    "            print(line_)\n",
    "            print(e)\n",
    "            break\n",
    "    df = pd.DataFrame(evaled)\n",
    "    alldf = df.drop(columns = ['friends'], axis=1)\n",
    "    alldf.to_csv(dataPath + \"user.csv\", index=False)\n",
    "    alldf.to_csv(dataPath + \"user.csv\", index=False)\n",
    "    \n",
    "    friendsdf = df[['user_id', 'friends']]\n",
    "    friendsdf.to_csv(dataPath + \"friends.csv\", index=False)\n",
    "#     friendsdf.to_csv(\"D:\\Projects\\YELP\\data\\friends.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "289f70e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_tip():\n",
    "    lines = []\n",
    "    with open(dataPath + \"yelp_academic_dataset_tip.json\", encoding=\"latin1\") as file:\n",
    "#     with open(\"D:\\Projects\\YELP\\data\\yelp_academic_dataset_tip.json\", encoding=\"latin1\") as file:\n",
    "        for line in file:\n",
    "            line = line.replace('\\/', ' ').replace('\\n', '').replace(':null', ': \"null\"')\n",
    "            lines.append(line)\n",
    "    evaled = []\n",
    "    for i, line_ in enumerate(lines):\n",
    "        if i%50000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            newline = ast.literal_eval(line_)\n",
    "            evaled.append(newline)\n",
    "        except Exception as e:\n",
    "            print(line_)\n",
    "            print(e)\n",
    "            break\n",
    "    df = pd.DataFrame(evaled)\n",
    "    df.to_csv(dataPath + \"tip.csv\", index=False)\n",
    "#     df.to_csv(\"D:\\Projects\\YELP\\data\\tip.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed5b4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_review():\n",
    "    lines = []\n",
    "    with open(dataPath + \"yelp_academic_dataset_review.json\", encoding=\"latin1\") as file:\n",
    "#     with open(\"D:\\Projects\\YELP\\data\\yelp_academic_dataset_review.json\", encoding=\"latin1\") as file:\n",
    "        for line in file:\n",
    "            line = line.replace('\\/', ' ').replace('\\n', '').replace(':null', ': \"null\"')\n",
    "            lines.append(line)\n",
    "    evaled = []\n",
    "    for i, line_ in enumerate(lines):\n",
    "        if i%50000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            newline = ast.literal_eval(line_)\n",
    "            evaled.append(newline)\n",
    "        except Exception as e:\n",
    "            print(line_)\n",
    "            print(e)\n",
    "            break\n",
    "    df = pd.DataFrame(evaled)\n",
    "    df.to_csv(dataPath + \"review.csv\", index=False)\n",
    "#     df.to_csv(\"D:\\Projects\\YELP\\data\\review.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18663cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert_review()\n",
    "# convert_tip()\n",
    "# convert_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4007b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78343f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test values outliers like 'monday': '0:0-10:30, 12:30-17:30'\n",
    "for val in hours['hours']:\n",
    "#     print(val)\n",
    "#     print('---')\n",
    "    if pd.notnull(val):\n",
    "        val = ast.literal_eval(val)\n",
    "        for k,v in val.items():\n",
    "            vals = v.split(',')\n",
    "            if len(vals) > 1:\n",
    "                print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
